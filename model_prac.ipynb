{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kihyun\\AppData\\Local\\Temp\\ipykernel_25696\\1046921996.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_dataset[total_dataset.label == 3].label = 2\n",
      "C:\\Users\\kihyun\\AppData\\Local\\Temp\\ipykernel_25696\\1046921996.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_dataset[total_dataset.label == 4].label = 3\n",
      "C:\\Users\\kihyun\\AppData\\Local\\Temp\\ipykernel_25696\\1046921996.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  total_dataset[total_dataset.label == 5].label = 4\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:58:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:58:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kihyun\\Codes\\mediapipe_kihyun\\model_prac.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kihyun/Codes/mediapipe_kihyun/model_prac.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m dep \u001b[39min\u001b[39;00m depth_ls:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kihyun/Codes/mediapipe_kihyun/model_prac.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     model \u001b[39m=\u001b[39m XGBClassifier(tree_method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m'\u001b[39m, gpu_id\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m ,n_estimators \u001b[39m=\u001b[39m estim, learning_rate \u001b[39m=\u001b[39m lr, max_depth \u001b[39m=\u001b[39m dep, early_stopping_rounds \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kihyun/Codes/mediapipe_kihyun/model_prac.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kihyun/Codes/mediapipe_kihyun/model_prac.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_valid)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kihyun/Codes/mediapipe_kihyun/model_prac.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     score \u001b[39m=\u001b[39m accuracy_score(y_hat, y_valid)\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1487\u001b[0m (\n\u001b[0;32m   1488\u001b[0m     model,\n\u001b[0;32m   1489\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1495\u001b[0m )\n\u001b[0;32m   1496\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1497\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1498\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1513\u001b[0m )\n\u001b[1;32m-> 1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1516\u001b[0m     params,\n\u001b[0;32m   1517\u001b[0m     train_dmatrix,\n\u001b[0;32m   1518\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1519\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1520\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1521\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1522\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1523\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1524\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1525\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1526\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1527\u001b[0m )\n\u001b[0;32m   1529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1530\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39;49mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    185\u001b[0m bst \u001b[39m=\u001b[39m cb_container\u001b[39m.\u001b[39mafter_training(bst)\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\callback.py:241\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    239\u001b[0m     metric_score \u001b[39m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[1;32m--> 241\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39many\u001b[39;49m(c\u001b[39m.\u001b[39;49mafter_iteration(model, epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhistory) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks)\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\callback.py:241\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    239\u001b[0m     metric_score \u001b[39m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[1;32m--> 241\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(c\u001b[39m.\u001b[39;49mafter_iteration(model, epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhistory) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\kihyun\\anaconda3\\envs\\cuda118\\Lib\\site-packages\\xgboost\\callback.py:426\u001b[0m, in \u001b[0;36mEarlyStopping.after_iteration\u001b[1;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[0;32m    424\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMust have at least 1 validation dataset for early stopping.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(evals_log\u001b[39m.\u001b[39mkeys()) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    428\u001b[0m \u001b[39m# Get data name\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata:\n",
      "\u001b[1;31mValueError\u001b[0m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "left_right = [\"left_\", \"right_\"]\n",
    "name_list = [\"chaeyun\", \"chanwoo\", \"inseo\", \"jaehoon\", \"jeongwoo\", \"junho\", \"kihyun\", \"suho\", \"sunghyun\", \"wonyoung\"]\n",
    "lf_rf = [\"_lf\", \"_rf\"]\n",
    "\n",
    "for ff in lf_rf:\n",
    "    filename = \"xgb_model\"+ff+\".model\"\n",
    "    total_dataset = pd.DataFrame()\n",
    "    for direction in left_right:\n",
    "        for name in name_list:\n",
    "            \n",
    "            person_data = pd.read_csv(\"XY_dataset/\"+direction+name+ff+\".csv\")\n",
    "            total_dataset = pd.concat((total_dataset, person_data), sort=False)\n",
    "    \n",
    "    ###### label 2 제거\n",
    "    total_dataset[total_dataset.label == 3].label = 2\n",
    "    total_dataset[total_dataset.label == 4].label = 3\n",
    "    total_dataset[total_dataset.label == 5].label = 4\n",
    "    X = total_dataset.iloc[:,1:100]\n",
    "    Y = total_dataset.iloc[:,100]\n",
    "    #X = torch.tensor(X).to(device)\n",
    "    #Y = torch.tensor(Y).to(device)\n",
    "    x_train_all, x_test, y_train_all, y_test = train_test_split(X,Y, test_size=0.1)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, test_size=0.1)\n",
    "\n",
    "    estim_ls = [300, 400, 500]\n",
    "    lr_ls = [0.08,0.1,0.15,0.2,0.25]\n",
    "    depth_ls = [4, 5, 6, 7]\n",
    "    \n",
    "    max_score = -1.0\n",
    "\n",
    "    for estim in estim_ls:\n",
    "        for lr in lr_ls:\n",
    "            for dep in depth_ls:\n",
    "                model = XGBClassifier(tree_method = 'gpu_hist', gpu_id=0 ,n_estimators = estim, learning_rate = lr, max_depth = dep, early_stopping_rounds = 10)\n",
    "                model.fit(x_train,y_train)\n",
    "                y_hat = model.predict(x_valid)\n",
    "                score = accuracy_score(y_hat, y_valid)\n",
    "                \n",
    "                if score > max_score:\n",
    "                    max_param=[estim, lr, dep]\n",
    "                    max_score = score\n",
    "    model = XGBClassifier(n_estimators = max_param[0], learning_rate = max_param[1], max_depth = max_param[2], random_state=32)\n",
    "    model.fit(x_train_all, y_train_all)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"accuracy of model\"+ ff + \"is :\", accuracy_score(y_pred, y_test))\n",
    "    print(\"best parameter : \", max_param)\n",
    "    model.save_model(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
